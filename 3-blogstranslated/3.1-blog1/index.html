<!doctype html><html lang=en class="js csstransforms3d"><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.134.3"><meta name=description content><meta name=author content="thienlh@thienlu.com"><link rel=icon href=../../images/favicon.png type=image/png><title>Blog 1 :: Internship Report</title> <link href=../../css/nucleus.css?1765276102 rel=stylesheet><link href=../../css/fontawesome-all.min.css?1765276102 rel=stylesheet><link href=../../css/hybrid.css?1765276102 rel=stylesheet><link href=../../css/featherlight.min.css?1765276102 rel=stylesheet><link href=../../css/perfect-scrollbar.min.css?1765276102 rel=stylesheet><link href=../../css/auto-complete.css?1765276102 rel=stylesheet><link href=../../css/atom-one-dark-reasonable.css?1765276102 rel=stylesheet><link href=../../css/theme.css?1765276102 rel=stylesheet><link href=../../css/hugo-theme.css?1765276102 rel=stylesheet><link href=../../css/theme-workshop.css?1765276102 rel=stylesheet><script src=../../js/jquery-3.3.1.min.js?1765276102></script><style>:root #header+#content>#left>#rlblock_left{display:none!important}</style></head><body data-url=../../3-blogstranslated/3.1-blog1/><nav id=sidebar class=showVisitedLinks><div id=header-wrapper><div id=header><a id=logo href=../../><svg id="Layer_1" data-name="Layer 1" viewBox="0 0 60 30" width="30%"><defs><style>.cls-1{fill:#fff}.cls-2{fill:#f90;fill-rule:evenodd}</style></defs><title>AWS-Logo_White-Color</title><path class="cls-1" d="M14.09 10.85a4.7 4.7.0 00.19 1.48 7.73 7.73.0 00.54 1.19.77.77.0 01.12.38.64.64.0 01-.32.49l-1 .7a.83.83.0 01-.44.15.69.69.0 01-.49-.23 3.8 3.8.0 01-.6-.77q-.25-.42-.51-1a6.14 6.14.0 01-4.89 2.3 4.54 4.54.0 01-3.32-1.19 4.27 4.27.0 01-1.22-3.2 4.28 4.28.0 011.46-3.4A6.06 6.06.0 017.69 6.46a12.47 12.47.0 011.76.13q.92.13 1.91.36V5.73a3.65 3.65.0 00-.79-2.66A3.81 3.81.0 007.86 2.3a7.71 7.71.0 00-1.79.22 12.78 12.78.0 00-1.79.57 4.55 4.55.0 01-.58.22h-.26q-.35.0-.35-.52V2a1.09 1.09.0 01.12-.58 1.2 1.2.0 01.47-.35A10.88 10.88.0 015.77.32 10.19 10.19.0 018.36.0a6 6 0 014.35 1.35 5.49 5.49.0 011.38 4.09zM7.34 13.38a5.36 5.36.0 001.72-.31A3.63 3.63.0 0010.63 12 2.62 2.62.0 0011.19 11a5.63 5.63.0 00.16-1.44v-.7a14.35 14.35.0 00-1.53-.28 12.37 12.37.0 00-1.56-.1 3.84 3.84.0 00-2.47.67A2.34 2.34.0 005 11a2.35 2.35.0 00.61 1.76A2.4 2.4.0 007.34 13.38zm13.35 1.8a1 1 0 01-.64-.16 1.3 1.3.0 01-.35-.65L15.81 1.51a3 3 0 01-.15-.67.36.36.0 01.41-.41H17.7a1 1 0 01.65.16 1.4 1.4.0 01.33.65l2.79 11 2.59-11A1.17 1.17.0 0124.39.6a1.1 1.1.0 01.67-.16H26.4a1.1 1.1.0 01.67.16 1.17 1.17.0 01.32.65L30 12.39 32.88 1.25A1.39 1.39.0 0133.22.6a1 1 0 01.65-.16h1.54a.36.36.0 01.41.41 1.36 1.36.0 010 .26 3.64 3.64.0 01-.12.41l-4 12.86a1.3 1.3.0 01-.35.65 1 1 0 01-.64.16H29.25a1 1 0 01-.67-.17 1.26 1.26.0 01-.32-.67L25.67 3.64l-2.56 10.7a1.26 1.26.0 01-.32.67 1 1 0 01-.67.17zm21.36.44a11.28 11.28.0 01-2.56-.29 7.44 7.44.0 01-1.92-.67 1 1 0 01-.61-.93v-.84q0-.52.38-.52a.9.9.0 01.31.06l.42.17a8.77 8.77.0 001.83.58 9.78 9.78.0 002 .2 4.48 4.48.0 002.43-.55 1.76 1.76.0 00.86-1.57 1.61 1.61.0 00-.45-1.16A4.29 4.29.0 0043 9.22l-2.41-.76A5.15 5.15.0 0138 6.78a3.94 3.94.0 01-.83-2.41 3.7 3.7.0 01.45-1.85 4.47 4.47.0 011.19-1.37 5.27 5.27.0 011.7-.86A7.4 7.4.0 0142.6.0a8.87 8.87.0 011.12.07q.57.07 1.08.19t.95.26a4.27 4.27.0 01.7.29 1.59 1.59.0 01.49.41.94.94.0 01.15.55v.79q0 .52-.38.52a1.76 1.76.0 01-.64-.2 7.74 7.74.0 00-3.2-.64 4.37 4.37.0 00-2.21.47 1.6 1.6.0 00-.79 1.48 1.58 1.58.0 00.49 1.18 4.94 4.94.0 001.83.92L44.55 7a5.08 5.08.0 012.57 1.6A3.76 3.76.0 0147.9 11a4.21 4.21.0 01-.44 1.93 4.4 4.4.0 01-1.21 1.47 5.43 5.43.0 01-1.85.93A8.25 8.25.0 0142.05 15.62z"/><path class="cls-2" d="M45.19 23.81C39.72 27.85 31.78 30 25 30A36.64 36.64.0 01.22 20.57c-.51-.46-.06-1.09.56-.74A49.78 49.78.0 0025.53 26.4 49.23 49.23.0 0044.4 22.53C45.32 22.14 46.1 23.14 45.19 23.81z"/><path class="cls-2" d="M47.47 21.21c-.7-.9-4.63-.42-6.39-.21-.53.06-.62-.4-.14-.74 3.13-2.2 8.27-1.57 8.86-.83s-.16 5.89-3.09 8.35c-.45.38-.88.18-.68-.32C46.69 25.8 48.17 22.11 47.47 21.21z"/></svg></a></div><div class=searchbox><label for=search-by><i class="fas fa-search"></i></label> <input data-search-input id=search-by type=search placeholder=Search...> <span data-search-clear><i class="fas fa-times"></i></span></div><script type=text/javascript src=../../js/lunr.min.js?1765276102></script><script type=text/javascript src=../../js/auto-complete.js?1765276102></script><script type=text/javascript>var baseurl="https://thienluhoan.github.io/workshop-template/"</script><script type=text/javascript src=../../js/search.js?1765276102></script></div><div class=highlightable><ul class=topics><li data-nav-id=/1-worklog/ title=Worklog class=dd-item><a href=../../1-worklog/><b>1. </b>Worklog
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/1-worklog/1.1-week1/ title="Week 1 Worklog" class=dd-item><a href=../../1-worklog/1.1-week1/><b>1.1. </b>Week 1 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.2-week2/ title="Week 2 Worklog" class=dd-item><a href=../../1-worklog/1.2-week2/><b>1.2. </b>Week 2 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.3-week3/ title="Week 3 Worklog" class=dd-item><a href=../../1-worklog/1.3-week3/><b>1.3. </b>Week 3 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.4-week4/ title="Week 4 Worklog" class=dd-item><a href=../../1-worklog/1.4-week4/><b>1.4. </b>Week 4 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.5-week5/ title="Week 5 Worklog" class=dd-item><a href=../../1-worklog/1.5-week5/><b>1.5. </b>Week 5 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.6-week6/ title="Week 6 Worklog" class=dd-item><a href=../../1-worklog/1.6-week6/><b>1.6. </b>Week 6 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.7-week7/ title="Week 7 Worklog" class=dd-item><a href=../../1-worklog/1.7-week7/><b>1.7. </b>Week 7 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.8-week8/ title="Week 8 Worklog" class=dd-item><a href=../../1-worklog/1.8-week8/><b>1.8. </b>Week 8 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.9-week9/ title="Week 9 Worklog" class=dd-item><a href=../../1-worklog/1.9-week9/><b>1.9. </b>Week 9 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.10-week10/ title="Week 10 Worklog" class=dd-item><a href=../../1-worklog/1.10-week10/><b>1.10. </b>Week 10 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.11-week11/ title="Week 11 Worklog" class=dd-item><a href=../../1-worklog/1.11-week11/><b>1.11. </b>Week 11 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.12-week12/ title="Week 12 Worklog" class=dd-item><a href=../../1-worklog/1.12-week12/><b>1.12. </b>Week 12 Worklog
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/2-proposal/ title=Proposal class=dd-item><a href=../../2-proposal/><b>2. </b>Proposal
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/3-blogstranslated/ title="Translated Blogs" class="dd-item
parent"><a href=../../3-blogstranslated/><b>3. </b>Translated Blogs
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/3-blogstranslated/3.1-blog1/ title="Blog 1" class="dd-item
active"><a href=../../3-blogstranslated/3.1-blog1/><b>3.1. </b>Blog 1
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/3-blogstranslated/3.2-blog2/ title="Blog 2" class=dd-item><a href=../../3-blogstranslated/3.2-blog2/><b>3.2. </b>Blog 2
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/3-blogstranslated/3.3-blog3/ title="Blog 3" class=dd-item><a href=../../3-blogstranslated/3.3-blog3/><b>3.3. </b>Blog 3
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/4-eventparticipated/ title="Events Participated" class=dd-item><a href=../../4-eventparticipated/><b>4. </b>Events Participated
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/4-eventparticipated/4.1-event1/ title="Event 1" class=dd-item><a href=../../4-eventparticipated/4.1-event1/><b>4.1. </b>Event 1
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/4-eventparticipated/4.2-event2/ title="Event 2" class=dd-item><a href=../../4-eventparticipated/4.2-event2/><b>4.2. </b>Event 2
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/4-eventparticipated/4.3-event3/ title="Event 3" class=dd-item><a href=../../4-eventparticipated/4.3-event3/><b>4.2. </b>Event 3
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/5-workshop/ title=Workshop class=dd-item><a href=../../5-workshop/><b>5. </b>Workshop
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/5-workshop/5.1-workshop-overview/ title=Introduction class=dd-item><a href=../../5-workshop/5.1-workshop-overview/><b>5.1. </b>Introduction
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.2-prerequiste/ title=Prerequiste class=dd-item><a href=../../5-workshop/5.2-prerequiste/><b>5.2. </b>Prerequiste
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.3-create-amplify/ title="Create Amplify backend" class=dd-item><a href=../../5-workshop/5.3-create-amplify/><b>5.3. </b>Create Amplify backend
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.4-aws-cognito/ title="Configure AWS Cognito" class=dd-item><a href=../../5-workshop/5.4-aws-cognito/>5.4. Configure AWS Cognito
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.5-create-ses/ title="Configure Amazon SES for email" class=dd-item><a href=../../5-workshop/5.5-create-ses/><b>5.5. </b>Configure Amazon SES for email
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.6-create-cloudwatch/ title="Configure Amazon CloudWatch" class=dd-item><a href=../../5-workshop/5.6-create-cloudwatch/><b>5.6. </b>Configure Amazon CloudWatch
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.7-create-iam-roles-policies/ title="Create IAM Roles-Policies" class=dd-item><a href=../../5-workshop/5.7-create-iam-roles-policies/><b>5.7. </b>Create IAM Roles-Policies
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.8-route-53/ title="Configure Amazon Route 53" class=dd-item><a href=../../5-workshop/5.8-route-53/><b>5.8. </b>Configure Amazon Route 53
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.9-cleanup/ title="Clean up" class=dd-item><a href=../../5-workshop/5.9-cleanup/><b>5.9. </b>Clean up
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/6-self-evaluation/ title=Self-Assessment class=dd-item><a href=../../6-self-evaluation/><b>6. </b>Self-Assessment
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/7-feedback/ title="Sharing and Feedback" class=dd-item><a href=../../7-feedback/><b>7. </b>Sharing and Feedback
<i class="fas fa-check read-icon"></i></a></li></ul><section id=shortcuts><h3>More</h3><ul><li><a class=padding href=https://www.facebook.com/groups/awsstudygroupfcj/><i class='fab fa-facebook'></i> AWS Study Group</a></li></ul></section><section id=prefooter><hr><ul><li><a class=padding><i class="fas fa-language fa-fw"></i><div class=select-style><select id=select-language onchange="location=this.value"><option id=en value=https://thienluhoan.github.io/workshop-template/3-blogstranslated/3.1-blog1/ selected>English</option><option id=vi value=https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.1-blog1/>Tiếng Việt</option></select><svg id="Capa_1" xmlns:xlink="http://www.w3.org/1999/xlink" width="255" height="255" viewBox="0 0 255 255" style="enable-background:new 0 0 255 255"><g><g id="arrow-drop-down"><polygon points="0,63.75 127.5,191.25 255,63.75"/></g></g></svg></div></a></li><li><a class=padding href=# data-clear-history-toggle><i class="fas fa-history fa-fw"></i> Clear History</a></li></ul></section><section id=footer><left><b>Workshop</b><br><img src="https://hitwebcounter.com/counter/counter.php?page=7920860&style=0038&nbdigits=9&type=page&initCount=0" title=Migrate alt="web counter" border=0></a><br><b><a href=https://cloudjourney.awsstudygroup.com/>Cloud Journey</a></b><br><img src="https://hitwebcounter.com/counter/counter.php?page=7830807&style=0038&nbdigits=9&type=page&initCount=0" title="Total CLoud Journey" alt="web counter" border=0>
</left><left><br><br><b>Last Updated</b><br><i><span id=lastUpdated style=color:orange></span>
</i><script>const today=new Date,formattedDate=today.toLocaleDateString("en-GB");document.getElementById("lastUpdated").textContent=formattedDate</script></left><left><br><br><b>Team</b><br><i><a href=https://www.facebook.com/groups/660548818043427 style=color:orange>First Cloud Journey</a><br></i></left><script async defer src=https://buttons.github.io/buttons.js></script></section></div></nav><section id=body><div id=overlay></div><div class="padding highlightable"><div><div id=top-bar><div id=breadcrumbs itemscope itemtype=http://data-vocabulary.org/Breadcrumb><span id=sidebar-toggle-span><a href=# id=sidebar-toggle data-sidebar-toggle><i class="fas fa-bars"></i> </a></span><span id=toc-menu><i class="fas fa-list-alt"></i></span> <span class=links><a href=../../>Internship Report</a> > <a href=../../3-blogstranslated/>Translated Blogs</a> > Blog 1</span></div><div class=progress><div class=wrapper><nav id=TableOfContents><ul><li><a href=#building-a-speech-intelligence-system-with-assemblyais-speech-to-text-model-from-aws-marketplace>Building a Speech Intelligence System with AssemblyAI&rsquo;s Speech-to-Text Model from AWS Marketplace</a></li></ul><ul><li><a href=#about-assemblyai>About AssemblyAI</a></li><li><a href=#solution-overview>Solution Overview</a></li><li><a href=#prerequisites>Prerequisites</a></li><li><a href=#solution-walkthrough>Solution Walkthrough</a></li><li><a href=#transcribing-audio-from-amazon-s3>Transcribing Audio from Amazon S3</a></li><li><a href=#transcribing-audio-from-a-local-file>Transcribing Audio from a Local File</a></li><li><a href=#speaker-diarization>Speaker Diarization</a></li><li><a href=#automatic-language-detection>Automatic Language Detection</a></li><li><a href=#pii-redaction>PII Redaction</a></li><li><a href=#conclusion>Conclusion</a></li><li><a href=#about-the-authors>About the Authors</a></li></ul></nav></div></div></div></div><div id=head-tags></div><div id=body-inner><h1>Blog 1</h1><h2 id=building-a-speech-intelligence-system-with-assemblyais-speech-to-text-model-from-aws-marketplace>Building a Speech Intelligence System with AssemblyAI&rsquo;s Speech-to-Text Model from AWS Marketplace</h2><p>Author: Shun Mao and Zackary Klebanoff</p><p>Published: April 16, 2025</p><p>Source: AWS Marketplace Blog</p><h1 id=introduction>Introduction</h1><p>Speech intelligence technology and Speech-to-Text (STT) have become essential as organizations collect thousands of hours of call recordings, meetings, and customer interactions each day. However, raw audio data alone cannot provide actionable insights — organizations need the capability to leverage intelligence to extract value from speech data at scale.</p><p>Speech intelligence combines speech recognition technology, natural language processing (NLP), and machine learning (ML) to convert audio data into actionable insights. Modern STT models are capable of transcribing conversations with high accuracy and work in tandem with other auxiliary tools to analyze sentiment, detect main topics, and create automatic summaries to provide deeper insights.</p><p>Speech intelligence and STT technologies are widely applied in various industries, such as call analytics, conversational intelligence, medical transcription, customer service, video content optimization, legal compliance, sales training and analysis, and more. With the rise of generative AI and increasingly advanced models, the demand for efficient STT models continues to grow in these applications.</p><hr><h2 id=about-assemblyai>About AssemblyAI</h2><p>AssemblyAI, an Independent Software Vendor (ISV) on AWS Marketplace, is a research-driven organization focused on advancing and democratizing speech AI technology globally. Founded in 2017, the company has built a team of interdisciplinary researchers, scientists, and engineers working towards developing state-of-the-art speech AI models, unlocking new possibilities for audio-based applications.</p><p>AssemblyAI&rsquo;s technology serves thousands of customers and hundreds of thousands of developers worldwide through a simple, developer-friendly API. AssemblyAI provides comprehensive speech AI capabilities, including:</p><ul><li><p>Core Speech-to-Text</p></li><li><p>Speaker Detection</p></li><li><p>Automatic Language Detection</p></li><li><p>Sentiment Analysis</p></li><li><p>Chapter Detection</p></li><li><p>PII (Personally Identifiable Information) Redaction</p></li></ul><p>AssemblyAI&rsquo;s Universal-2 model demonstrates the company&rsquo;s commitment to pushing the limits of speech AI technology. This model achieves high accuracy by addressing key challenges in speech recognition, improving the recognition of proper nouns, text formatting, capitalization, and accurate timestamp creation. AssemblyAI takes a research-based approach to building robust and easily integrable speech AI models.</p><p>This article will guide you on how to get started with AssemblyAI&rsquo;s API on AWS Marketplace, while also building an initial Proof of Concept (POC) by making API calls in just a few simple steps.</p><hr><h2 id=solution-overview>Solution Overview</h2><p>AssemblyAI&rsquo;s Speech-to-Text service processes audio through a two-stage pipeline.
In the first stage, the system uses the Universal-2 ASR (Automatic Speech Recognition) model — a Conformer RNN-T model with 600 million parameters, trained on 12.5 million hours of multilingual audio data. This model can transcribe speech to text while effectively handling complex situations, such as multiple speakers, regional accents, and background noise.
In the second stage, the system applies neural models to format the text, adding punctuation, capitalization, and text normalization to produce a clean, readable, and professional transcript.</p><p>In addition to core transcription, users can activate additional AI models that run in parallel with the main ASR process. These models include:</p><ul><li><p>Speaker Identification – determining who is speaking in a conversation.</p></li><li><p>Sentiment Analysis – understanding the tone and sentiment in speech.</p></li><li><p>Topic Detection – automatically classifying the conversation&rsquo;s content.</p></li><li><p>Content Summarization – extracting key points and summaries.</p></li><li><p>PII Redaction – ensuring compliance with privacy requirements.</p></li></ul><p>All these models seamlessly integrate through the same API interface, making it easy for developers to incorporate and expand speech analytics capabilities.</p><img src=../../images/blog1.png alt="High-level Architecture Diagram for AssemblyAI's Transcription API" width=600><blockquote><p><em>Figure 1: High-level Architecture Diagram for AssemblyAI&rsquo;s Transcription API</em></p></blockquote><hr><h2 id=prerequisites>Prerequisites</h2><p>Before you begin, ensure you have the following:</p><ul><li><p>An Amazon Web Services (AWS) account with access to Amazon Simple Storage Service (Amazon S3).</p></li><li><p>AssemblyAI&rsquo;s API service is available for purchase on AWS Marketplace. You can also sign up for a trial account directly on AssemblyAI’s website.</p></li><li><p>Once you&rsquo;ve created your AssemblyAI account, store your API key securely for use in the next steps.</p></li></ul><p>Next, run the following Python code to prepare for the implementation scenarios in the solution walkthrough:</p><pre><code>!pip install assemblyai

import assemblyai as aai

aai.settings.api_key = &quot;xxxxxxxx&quot;  # Your AssemblyAI API key
</code></pre><hr><h2 id=solution-walkthrough>Solution Walkthrough</h2><p>In this section, we will explore five use cases where AssemblyAI&rsquo;s API can deliver significant value. Each case is accompanied by a code snippet, enabling readers to experiment within their own environment.</p><ol><li><p>Transcribing Audio from a Local File</p></li><li><p>Transcribing an Audio File from Amazon S3</p></li><li><p>Speaker Diarization</p></li><li><p>Automatic Language Detection</p></li><li><p>PII Redaction</p></li></ol><hr><h2 id=transcribing-audio-from-amazon-s3>Transcribing Audio from Amazon S3</h2><p>In many organizations, audio data is stored in cloud storage services like Amazon S3. To transcribe an audio file from an S3 bucket, AssemblyAI requires temporary access to that file.</p><p>To grant this access, you need to create a pre-signed URL, which is a special link that provides access to the file for a limited time.</p><p>For more details on how to create a pre-signed URL, refer to the AWS documentation: “Sharing Objects with Pre-signed URLs.”</p><p>Execute the following Python code to perform transcription:</p><pre><code>import requests
import time

p_url = &quot;S3 pre-signed url&quot;

assembly_key = &quot;xxxxxxxx&quot;  # Your AssemblyAI API key

# Use the API key for authentication
headers = {&quot;authorization&quot;: assembly_key, &quot;content-type&quot;: &quot;application/json&quot;}

# AssemblyAI's transcription API endpoint
upload_endpoint = &quot;https://api.assemblyai.com/v2/transcript&quot;

# Use the pre-signed URL for the audio file in the POST request
json = {&quot;audio_url&quot;: p_url}

# POST request to queue the audio file for transcription
post_response = requests.post(upload_endpoint, json=json, headers=headers)

# Get the processing endpoint
get_endpoint = upload_endpoint + &quot;/&quot; + post_response.json()[&quot;id&quot;]

# GET request to check the transcription status
get_response = requests.get(get_endpoint, headers=headers)

# If transcription is not yet complete, wait until it's finished
while get_response.json()[&quot;status&quot;] != &quot;completed&quot;:
    get_response = requests.get(get_endpoint, headers=headers)
    time.sleep(5)

# When transcription is complete, print the result
print(get_response.json()[&quot;text&quot;])
</code></pre><hr><h2 id=transcribing-audio-from-a-local-file>Transcribing Audio from a Local File</h2><p>This is a simple setup where audio files are stored in the local directory where the code is executed.</p><p>AssemblyAI&rsquo;s API supports most popular audio and video formats like mp3, m4a, m4p, wav, or wma.</p><p>For optimal recognition quality, it&rsquo;s recommended to use the raw format of the audio file rather than converting it to another format.</p><p>For more details about supported audio file formats, refer to AssemblyAI’s blog.</p><p>Download a publicly available audio file from AssemblyAI&rsquo;s website, and save it to your local directory.</p><p>Execute the following code to transcribe the file:</p><pre><code># Transcribe a local audio file
transcriber = aai.Transcriber()
transcript = transcriber.transcribe(&quot;./Audios/ford_clip_trimmed.mp3&quot;)

print(transcript.text)
</code></pre><hr><h2 id=speaker-diarization>Speaker Diarization</h2><p>Speaker diarization is an important part of audio processing, as it addresses the challenge of identifying who speaks and when in a recording. This capability is essential for many tasks, such as improving clarity and structure, supporting advanced analytics, and enabling content personalization.</p><p>Execute the following code to perform transcription:</p><pre><code>config = aai.TranscriptionConfig(speaker_labels=True)
transcriber = aai.Transcriber(config=config)

FILE_URL = &quot;https://github.com/AssemblyAI-Examples/audio-examples/raw/main/20230607_me_canadian_wildfires.mp3&quot;

transcript = transcriber.transcribe(FILE_URL)

# Extract all the speech utterances from the response
utterances = transcript.utterances

# For each utterance, print the speaker and their speech
for utterance in utterances:
    speaker = utterance.speaker
    text = utterance.text
    print(f&quot;Speaker {speaker}: {text}&quot;)
</code></pre><hr><h2 id=automatic-language-detection>Automatic Language Detection</h2><p>Automatic language detection is another key feature in audio analysis, as it helps the system process and understand spoken content more accurately and effectively.</p><p>This feature enhances the user experience in multilingual applications and allows for customization based on specific languages.</p><p>Execute the following code to perform transcription:</p><pre><code>config = aai.TranscriptionConfig(language_detection=True)
transcriber = aai.Transcriber(config=config)

FILE_URL = &quot;https://assembly.ai/news.mp4&quot;

transcript = transcriber.transcribe(FILE_URL)

print(transcript.json_response['language_code'])
</code></pre><hr><h2 id=pii-redaction>PII Redaction</h2><p>Security is a top priority at AWS and AssemblyAI.</p><p>The PII redaction feature provided by AssemblyAI helps maintain privacy and security for sensitive information, allowing customers to build secure and compliant applications without legal or regulatory risks.</p><p>Users can control which types of sensitive data (e.g., credit card numbers, email addresses, phone numbers) to redact through configuration, as demonstrated in the following code snippet:</p><pre><code>config = aai.TranscriptionConfig()

config.set_redact_pii( 
  policies=[
      aai.PIIRedactionPolicy.credit_card_number,
      aai.PIIRedactionPolicy.email_address,
      aai.PIIRedactionPolicy.location,
      aai.PIIRedactionPolicy.person_name,
      aai.PIIRedactionPolicy.phone_number,
  ], 
  substitution=aai.PIISubstitutionPolicy.hash, 
)

transcriber = aai.Transcriber(config=config)

FILE_URL = &quot;https://example.org/audio.mp3&quot; 

transcript = transcriber.transcribe(FILE_URL)

print(transcript.text)
</code></pre><hr><h2 id=conclusion>Conclusion</h2><p>AssemblyAI is committed to building a high-quality API platform for developers to convert and understand speech data using AI, enabling the creation of innovative products and services.</p><p>AssemblyAI&rsquo;s speech-to-text models address critical challenges in the transcription process, and their latest model — Universal-2 — focuses on solving &ldquo;edge-case&rdquo; issues that impact real-world speech AI, such as improving accuracy for numbers, special characters, and rare words.</p><p>Learn more about the improvements in Universal-2: [Read AssemblyAI&rsquo;s Blog]
See how AssemblyAI compares to competitors: [View Performance Comparison Chart]
Explore the research behind Universal-2: [Learn More About Research]</p><p>You can start using AssemblyAI&rsquo;s API by visiting the product page on AWS Marketplace or by creating an account directly on AssemblyAI&rsquo;s website.</p><hr><h2 id=about-the-authors>About the Authors</h2><p>Shun Mao</p><pre><code>    Shun Mao is a Senior Partner Solution Architect in the Independent Software Vendor (ISV) partner group, specializing in Artificial Intelligence and Machine Learning (AI/ML) at Amazon Web Services (AWS). He has many years of experience in data science, analytics, AI, and cloud computing across various industries, including oil and gas and pharmaceuticals. At AWS, he supports strategic AI/ML partners in developing creative products and solutions that deliver business value to customers. Outside of work, Shun enjoys fishing, traveling, and playing table tennis.
</code></pre><p>Zackary Klebanoff</p><pre><code>    Zackary Klebanoff is a Senior Solution Architect at AssemblyAI. He has several years of experience helping customers leverage speech AI technology to build exceptional products and applications. Throughout his career, he has worked at startups, helping them grow by bridging the gap between technology and practical applications. Outside of work, Zackary enjoys playing basketball, attending concerts, and supporting the Philadelphia Eagles football team.
</code></pre><hr><footer class=footline></footer></div></div><div id=navigation><a class="nav nav-prev" href=../../3-blogstranslated/ title="Translated Blogs"><i class="fa fa-chevron-left"></i></a> <a class="nav nav-next" href=../../3-blogstranslated/3.2-blog2/ title="Blog 2" style=margin-right:0><i class="fa fa-chevron-right"></i></a></div></section><div style=left:-1000px;overflow:scroll;position:absolute;top:-1000px;border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px><div style=border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px></div></div><script src=../../js/clipboard.min.js?1765276102></script><script src=../../js/perfect-scrollbar.min.js?1765276102></script><script src=../../js/perfect-scrollbar.jquery.min.js?1765276102></script><script src=../../js/jquery.sticky.js?1765276102></script><script src=../../js/featherlight.min.js?1765276102></script><script src=../../js/highlight.pack.js?1765276102></script><script>hljs.initHighlightingOnLoad()</script><script src=../../js/modernizr.custom-3.6.0.js?1765276102></script><script src=../../js/learn.js?1765276102></script><script src=../../js/hugo-learn.js?1765276102></script><link href=../../mermaid/mermaid.css?1765276102 rel=stylesheet><script src=../../mermaid/mermaid.js?1765276102></script><script>mermaid.initialize({startOnLoad:!0})</script><script>(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,(e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date),(i=t.createElement(n),a=t.getElementsByTagName(n)[0]),i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-158079754-2","auto"),ga("send","pageview")</script></body></html>